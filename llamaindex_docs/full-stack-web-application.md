# Full-Stack Web Application#

原始連結：https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/

# Full-Stack Web Application#

[#](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/#full-stack-web-application)

LlamaIndex can be integrated into a downstream full-stack web application. It can be used in a backend server (such as Flask), packaged into a Docker container, and/or directly used in a framework such as Streamlit.

We provide tutorials and resources to help you get started in this area:

- [Fullstack Application Guide](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/fullstack_app_guide/) shows you how to build an app with LlamaIndex as an API and a TypeScript+React frontend
- [Fullstack Application with Delphic](https://docs.llamaindex.ai/en/stable/understanding/putting_it_all_together/apps/fullstack_with_delphic/) walks you through using LlamaIndex with a production-ready web app starter template called Delphic.
- The [LlamaIndex Starter Pack](https://github.com/logan-markewich/llama_index_starter_pack) provides very basic flask, streamlit, and docker examples for LlamaIndex.

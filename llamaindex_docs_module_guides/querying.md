# Querying#

ÂéüÂßãÈÄ£ÁµêÔºöhttps://docs.llamaindex.ai/en/stable/module_guides/querying/

# Querying#

[#](https://docs.llamaindex.ai/en/stable/module_guides/querying/#querying)

Querying is the most important part of your LLM application. To learn more about getting a final product that you can deploy, check out the [query engine](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/), [chat engine](https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/).

If you wish to combine advanced reasoning with tool use, check out our [agents](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/) guide.

## Query Workflows#

[#](https://docs.llamaindex.ai/en/stable/module_guides/querying/#query-workflows)

You can create workflows for querying with ease, using our event-driven Workflow interface. Check out our [workflow guide](https://docs.llamaindex.ai/en/stable/module_guides/workflow/) for more details.

```
Workflow
```

Otherwise check out how to use our query modules as standalone components üëá.

## Query Modules#

[#](https://docs.llamaindex.ai/en/stable/module_guides/querying/#query-modules)

- [Query Engines](https://docs.llamaindex.ai/en/stable/module_guides/deploying/query_engine/)
- [Chat Engines](https://docs.llamaindex.ai/en/stable/module_guides/deploying/chat_engines/)
- [Agents](https://docs.llamaindex.ai/en/stable/module_guides/deploying/agents/)
- [Retrievers](https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/)
- [Response Synthesizers](https://docs.llamaindex.ai/en/stable/module_guides/querying/response_synthesizers/)
- [Routers](https://docs.llamaindex.ai/en/stable/module_guides/querying/router/)
- [Node Postprocessors](https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/)
- [Structured Outputs](https://docs.llamaindex.ai/en/stable/module_guides/querying/structured_outputs/)
